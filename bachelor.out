\BOOKMARK [0][-]{chapter*.1}{Acknowledgments}{}% 1
\BOOKMARK [0][-]{chapter.1}{Introduction}{}% 2
\BOOKMARK [1][-]{section.1.1}{Section Name}{chapter.1}% 3
\BOOKMARK [1][-]{section.1.2}{Another Section}{chapter.1}% 4
\BOOKMARK [0][-]{chapter.2}{Literature Review}{}% 5
\BOOKMARK [1][-]{section.2.1}{Natural Language Processing}{chapter.2}% 6
\BOOKMARK [1][-]{section.2.2}{Artificial Neural Networks}{chapter.2}% 7
\BOOKMARK [2][-]{subsection.2.2.1}{Feed Forward Neural Networks}{section.2.2}% 8
\BOOKMARK [2][-]{subsection.2.2.2}{Recurrent Neural Networks}{section.2.2}% 9
\BOOKMARK [2][-]{subsection.2.2.3}{Convolution Neural Networks}{section.2.2}% 10
\BOOKMARK [1][-]{section.2.3}{Speech Recognition}{chapter.2}% 11
\BOOKMARK [2][-]{subsection.2.3.1}{End-to-End Speech Recognition}{section.2.3}% 12
\BOOKMARK [2][-]{subsection.2.3.2}{Feature Extraction}{section.2.3}% 13
\BOOKMARK [2][-]{subsection.2.3.3}{Connectionist Temporal Classification graves2006connectionist}{section.2.3}% 14
\BOOKMARK [1][-]{section.2.4}{Text Analytics}{chapter.2}% 15
\BOOKMARK [2][-]{subsection.2.4.1}{Encoder-Decoder Architecture}{section.2.4}% 16
\BOOKMARK [2][-]{subsection.2.4.2}{Attention Mechanism}{section.2.4}% 17
\BOOKMARK [2][-]{subsection.2.4.3}{The Transformer}{section.2.4}% 18
\BOOKMARK [2][-]{subsection.2.4.4}{Bidirectional Encoder from Transformer \(BERT\)}{section.2.4}% 19
\BOOKMARK [0][-]{chapter.3}{Methodology}{}% 20
\BOOKMARK [1][-]{section.3.1}{Datasets}{chapter.3}% 21
\BOOKMARK [2][-]{subsection.3.1.1}{ASR Datasets}{section.3.1}% 22
\BOOKMARK [2][-]{subsection.3.1.2}{Text Classifier Datasets}{section.3.1}% 23
\BOOKMARK [0][-]{chapter.4}{Results}{}% 24
\BOOKMARK [0][-]{chapter.5}{Conclusion}{}% 25
\BOOKMARK [0][-]{chapter.6}{Future Work}{}% 26
\BOOKMARK [0][-]{section*.52}{Appendix}{}% 27
\BOOKMARK [0][-]{appendix.A}{Lists}{}% 28
\BOOKMARK [1][-]{section*.53}{List of Abbreviations}{appendix.A}% 29
\BOOKMARK [1][-]{appendix*.54}{List of Figures}{appendix.A}% 30
\BOOKMARK [0][-]{appendix*.55}{References}{}% 31
