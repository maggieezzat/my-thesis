\BOOKMARK [0][-]{chapter*.1}{Acknowledgments}{}% 1
\BOOKMARK [0][-]{chapter.1}{Introduction}{}% 2
\BOOKMARK [1][-]{section.1.1}{Section Name}{chapter.1}% 3
\BOOKMARK [1][-]{section.1.2}{Another Section}{chapter.1}% 4
\BOOKMARK [0][-]{chapter.2}{Background}{}% 5
\BOOKMARK [1][-]{section.2.1}{Natural Language Processing}{chapter.2}% 6
\BOOKMARK [1][-]{section.2.2}{Artificial Neural Networks}{chapter.2}% 7
\BOOKMARK [2][-]{subsection.2.2.1}{Feed Forward Neural Networks}{section.2.2}% 8
\BOOKMARK [2][-]{subsection.2.2.2}{Recurrent Neural Networks}{section.2.2}% 9
\BOOKMARK [2][-]{subsection.2.2.3}{Convolution Neural Networks}{section.2.2}% 10
\BOOKMARK [1][-]{section.2.3}{Speech Recognition}{chapter.2}% 11
\BOOKMARK [2][-]{subsection.2.3.1}{End-to-End Speech Recognition}{section.2.3}% 12
\BOOKMARK [2][-]{subsection.2.3.2}{Feature Extraction}{section.2.3}% 13
\BOOKMARK [2][-]{subsection.2.3.3}{Building the Model}{section.2.3}% 14
\BOOKMARK [2][-]{subsection.2.3.4}{Computing the Loss}{section.2.3}% 15
\BOOKMARK [1][-]{section.2.4}{Text Analytics}{chapter.2}% 16
\BOOKMARK [2][-]{subsection.2.4.1}{Encoder-Decoder Architecture}{section.2.4}% 17
\BOOKMARK [2][-]{subsection.2.4.2}{Attention Mechanism}{section.2.4}% 18
\BOOKMARK [2][-]{subsection.2.4.3}{The Transformer}{section.2.4}% 19
\BOOKMARK [2][-]{subsection.2.4.4}{Bidirectional Encoder from Transformer \(BERT\)}{section.2.4}% 20
\BOOKMARK [0][-]{chapter.3}{Conclusion}{}% 21
\BOOKMARK [0][-]{chapter.4}{Future Work}{}% 22
\BOOKMARK [0][-]{section*.36}{Appendix}{}% 23
\BOOKMARK [0][-]{appendix.A}{Lists}{}% 24
\BOOKMARK [1][-]{section*.37}{List of Abbreviations}{appendix.A}% 25
\BOOKMARK [1][-]{appendix*.38}{List of Figures}{appendix.A}% 26
\BOOKMARK [0][-]{appendix*.39}{References}{}% 27
