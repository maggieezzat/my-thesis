\chapter{Methodology}
\label{chap:methodology}

In this chapter, the methodology used to implement the system is illustrated. Firstly, an overview of the system is discussed, along with the datasets used. Secondly, an interpretation of the choice of architecture and decisions is elaborated. Eventually, the system implementation steps are demonstrated in detail.



\section{System Overview and Datasets} 
\label{meth:s1}

\includefig{0.6}{automated_dispatcher_actions_system.png}{Automated Dispatcher Actions System comprising two sub-systems: Automatic Speech Recognition unit taking input as raw speech from the driver. The text output is fed into a trained Text Classifier which issues the proper action accordingly.}{Fig:10}

As discussed earlier, the main purpose of this study is to implement a system able to issue dispatcher actions automatically when provided with audio signals from the vehicle driver, hence, introducing more automaton in the control-center. 

Our system consists of two sub-systems, as shown in figure \ref{Fig:10}, the first sub-system is the \ac{ASR} unit, which takes as input raw speech waveforms produced by the driver, and produces the information in a text form. Then the text is passed to a trained Text Classifier, which given the text information from the \ac{ASR}, issues the corresponding appropriate dispatcher action.

TODO IN THE CHOICE OF ARCHITECTURE NLP PROBLEMS TO MAKE AN END TO END SYSTEM


\subsection{\ac{ASR} Datasets}
\label{meth:sub1}

End-to-End \ac{ASR} systems require large amounts of transcribed audio data. For this purpose we make use of three open-source German datasets and clean them. We list the three datasets here with the cleaning operations performed for each. 
%#TODO Transcriptions cleaning


\subsubsection{\RomanNumeralCaps{1}. Common Voice}
\label{meth:subsubsub1}

Common Voice is the largest open source, multi-language dataset of voices available for use. It is managed by Mozilla and was collected by volunteers on-line who were either recording samples or validating other samples. Mozilla began work on this project in 2017 and contribution to the dataset continues up till now. 
For our \ac{ASR}, the German subset of the dataset was selected. It incorporates 340 total hours, with 325 validated hours and 15 invalidated hours which we excluded. The dataset has 5007 speakers but as we discarded the invalidated utterances we end up with only 4823 speakers. 
All the utterances were in \enquote{mp3} format and sampled using a sampling rate of $44 kHz$ so we converted them to \enquote{wav} format and we performed down-sampling to obtain sample rate of $16 kHz$. We checked for any corrupted files but there were none.


\subsubsection{\RomanNumeralCaps{2}. M-AILABS Speech Dataset}
\label{meth:subsub2}
M-AILABS Speech Dataset is an open-source multi-lingual dataset provided by Munich Artificial Intelligence Laboratories GmbH. Most of the data is based on LibriVox \footnote{https://librivox.org} and Project Gutenberg \footnote{https://www.gutenberg.org}. We make use of the German subset which is 237 hours 22 minutes with a total of 5 speakers. The data is available in \enquote{wav} format and sample rate of $16 kHz$ so we perform no modifications. We also check for corrupted files but all of them were healthy.

\subsubsection{\RomanNumeralCaps{3}. German Speech Data \cite{radeck2015open}}
\label{meth:subsub3}

This open-source corpus is provided by Technische Universit{\"a}t Darmstadt. It has 36 hours read by 180 speakers, and recorded using 5 different microphones simultaneously. They made use of the KisRecord \footnote{http://kisrecord.sourceforge.net} toolkit, which allows for recording with multiple microphones concurrently. Their target was distant speech recognition, thus a distance of one meter between speakers and microphones was chosen. The sentences which volunteers were provided to read were extracted randomly from three text resources: German Wikipedia, German section of the European Parliament transcriptions, short commands for command-and-control settings. Unfortunately, there were some corrupted files in the dataset, which we discarded.



TODO SPEAKER INDEPENDENT CLASSIFICATION



\subsection{Text Classifier Datasets}
\label{meth:sub2}

\subsubsection{\RomanNumeralCaps{1}. German Wikipedia Dump}
\label{meth:subsub4}
\subsubsection{\RomanNumeralCaps{2}. 10K German Articles}
\label{meth:subsub5}


\section{Automatic Speech Recognition Unit} 
\label{meth:s3}

\section{Text Classifier Unit} 
\label{meth:s4}
