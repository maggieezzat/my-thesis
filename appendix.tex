\appendix
\renewcommand{\appendixtocname}{Appendix}
\renewcommand{\appendixpagename}{\appendixtocname}
\addappheadtotoc
\setboolean{@twoside}{false}
\appendixpage

\chapter{Lists}
\addcontentsline{toc}{section}{List of Abbreviations}
\begin{acronym}[\hspace{3cm}]
  \acro{NLP}{Natural Language Processing}
  \acro{NLG}{Natural Language Generation}
  \acro{NLU}{Natural Language Understanding}
  \acro{ANN}{Artificial Neural Network}
  \acro{FNN}{Feed Forward Neural Network}
  \acro{MLP}{Multi Layer Perceptrons}
  \acro{RNN}{Recurrent Neural Network}
  \acro{BPTT}{Backpropagation Through Time}
  \acro{BRNN}{Bidirectional Recurrent Neural Network}
  \acro{LSTM}{Long Short-Term Memory}
  \acro{GRU}{Gated Recurrent Unit}
  \acro{ASR}{Automatic Speech Recognition}
  \acro{MFCC}{Mel-Frequency Cepstral Coefficents}
  \acro{FFT}{Fast Forier Transform}
  \acro{DCT}{Discrete Cosine Transform}
  \acro{CTC}{Connectionist Temporal Classification}
  \acro{HMM}{Hidden Markov Model}
  \acro{CNN}{Convolutional Neural Network}
  \acro{FSM}{Finite State Machines}
  \acro{BERT}{Bidirectional Encoder from Transformer}
  \acro{MLM}{Masked LM}
  \acro{GMM}{Gaussian Mixture Model}
  \acro{TDNN}{Time-Delayed Neural Networks}
  \acro{SWC}{Spoken Wikipedia Corpus}
  \acro{WER}{Word Error Rate}
  \acro{CER}{Character Error Rate}
  \acro{TPU}{Tensor Processing Unit }
  \acro{ASIC}{Application-Specific Integrated Circuit}
  \acro{HBM}{High Bandwidth Memory}
  \acro{XLA}{Accelerated Linear Algebra}
  \acro{VM}{Virtual Machine}
  \acro{T2T}{Tensor2Tensor}
\end{acronym}
\clearpage
\listoffigures
\addcontentsline{toc}{section}{List of Figures}
% \listoftables
% \addcontentsline{toc}{section}{List of Tables}
